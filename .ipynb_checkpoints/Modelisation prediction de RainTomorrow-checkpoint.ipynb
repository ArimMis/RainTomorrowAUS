{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix,f1_score,accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "import xgboost \n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/ariim/Desktop/RainNextDay/weatherAUS.csv\", sep =\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140787, 19)\n"
     ]
    }
   ],
   "source": [
    "df.dropna(subset=[\"RainTomorrow\",\"RainToday\"],inplace=True)\n",
    "for var in df.columns.tolist():\n",
    "    if (df[var].isna().sum()/df.shape[0])*100<20:\n",
    "        if df[var].dtypes==\"object\":\n",
    "            df[var].fillna(df[var].mode().iloc[0],inplace=True)\n",
    "        else:\n",
    "            df[var].fillna(df[var].median(),inplace=True)\n",
    "    else:\n",
    "        df.drop([var],axis=1,inplace=True)\n",
    "\n",
    "        print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"]=pd.to_datetime(df[\"Date\"],format=\"%Y-%m-%d\")\n",
    "df[\"Month\"]=df[\"Date\"].dt.month\n",
    "month={1:\"Janvier\",2:\"Fevrier\",3:\"Mars\",4:\"Avril\",5:\"Mai\",6:\"Juin\",7:\"Juillet\",8:\"Aout\",9:\"Septembre\",10:\"Octobre\",11:\"Novembre\",12:\"Decembre\"}\n",
    "df[\"Month\"]=df[\"Month\"].map(month)\n",
    "df.drop([\"Date\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "for idx in IQR.index:\n",
    "    \n",
    "    df=df[((df[idx]>(Q1[idx] - 1.5 * IQR[idx]))&(df[idx]<(Q3[idx] + 1.5 * IQR[idx])))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import LinearSVC\n",
    "# from sklearn.feature_selection import SelectFromModel\n",
    "# lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X, y)\n",
    "# model = SelectFromModel(lsvc, prefit=True)\n",
    "# X = model.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression()\n",
    "rf = RandomForestClassifier()\n",
    "svc = SVC()\n",
    "xg = xgboost.XGBClassifier()\n",
    "md = [{ \"name\": \"linear regression\",\"model\": lr, \"param\":{ \"penalty\":[\"l1\",\"l2\"],\n",
    "                                 \"solver\":[\"newton-cg\", \"lbfgs\", \"liblinear\",\"sag\", \"saga\"]\n",
    "                               }\n",
    "      },\n",
    "       {\n",
    "         \"name\": \"random forest\",\"model\":rf , \"param\":{\n",
    "                                 \"n_estimators\":[100,150,200],\"criterion\":[\"gini\",\"entropy\"],\"max_features\":[\"sqrt\", \"log2\"],\"warm_start\":[False,True]\n",
    "                             }  \n",
    "       },\n",
    "#        {\n",
    "#          \"name\": \"support vector\",\"model\":svc , \"param\":{\n",
    "#                                  \"C\":[1.0,0.5,2,0.3],\n",
    "#                                  \"kernel\":[\"linear\",\"poly\", \"rbf\", \"sigmoid\", \"precomputed\"],\n",
    "#                                  \"degree\":[3,4],\n",
    "#                                  \"decision_function_shape\":[\"ovo\",\"ovr\"]\n",
    "#                              }  \n",
    "#        },\n",
    "       {\n",
    "         \"name\": \"xgboost\",\"model\": xg , \"param\":{\n",
    "                                  'objective':['binary:logistic'],\n",
    "                                  'learning_rate': [0.05,0.01,0.03],\n",
    "                                  'n_estimators': [100,300,500],\n",
    "                                  'missing':[-999]}\n",
    "                             \n",
    "       }\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col(df,location,y):\n",
    "    lst_=df.columns.tolist()\n",
    "    lst_.remove(y)\n",
    "    X=df[df[\"Location\"]==location].copy()\n",
    "    X=X[lst_]\n",
    "    X.drop(\"Location\",axis=1,inplace=True)\n",
    "    X=pd.get_dummies(X)\n",
    "    return X.columns.tolist()\n",
    "list_col={}\n",
    "for loc in df.Location.unique().tolist():\n",
    "    print(loc)\n",
    "    list_col[loc]=col(df,loc,\"RainTomorrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"list_col\",\"wb\") as file:\n",
    "    pickle.dump(list_col,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelise_gal(df,y,map_y,model_list):\n",
    "    smote = SMOTE()\n",
    "    lst_=df.columns.tolist()\n",
    "    lst_.remove(y)\n",
    "    df_=df.copy()\n",
    "    X=df_[lst_]\n",
    "    y=df[y].map(map_y)\n",
    "    X=pd.get_dummies(X)\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(X)\n",
    "    X = sc.transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.30,stratify=y, random_state=42)\n",
    "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "    ret={}\n",
    "    for i in range(len(md)):\n",
    "        print(\"     \",md[i][\"name\"])\n",
    "        clf = GridSearchCV(md[i][\"model\"], md[i][\"param\"],cv=5,scoring=[\"f1\"],refit='f1',n_jobs=-1)\n",
    "        clf.fit(X_train, y_train)\n",
    "        ret[md[i][\"name\"]]={\"estimator\":clf.best_estimator_,\"best_param\":clf.best_params_,\"score\":clf.best_score_ ,\"scaler\":sc,\"X_test\":X_test,\"y_test\":y_test}\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelise(df,location,y,map_y,model_list):\n",
    "    smote = SMOTE()\n",
    "    lst_=df.columns.tolist()\n",
    "    lst_.remove(y)\n",
    "    X=df[df[\"Location\"]==location].copy()\n",
    "    y=X[y].map(map_y)\n",
    "    X=X[lst_]\n",
    "    X.drop(\"Location\",axis=1,inplace=True)\n",
    "    X=pd.get_dummies(X)\n",
    "    sc = StandardScaler()\n",
    "    X = sc.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.30,stratify=y, random_state=42)\n",
    "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "    ret={}\n",
    "    for i in range(len(md)):\n",
    "        print(\"     \",md[i][\"name\"])\n",
    "        clf = GridSearchCV(md[i][\"model\"], md[i][\"param\"],cv=5,scoring=[\"f1\"],refit='f1',n_jobs=-1)\n",
    "        clf.fit(X_train, y_train)\n",
    "        ret[md[i][\"name\"]]={\"estimator\":clf.best_estimator_,\"best_param\":clf.best_params_,\"score\":clf.best_score_, \"scaler\":sc,\"X_test\":X_test,\"y_test\":y_test}\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Albury\n",
      "      linear regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ariim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      random forest\n",
      "      xgboost\n",
      "BadgerysCreek\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "Cobar\n",
      "      linear regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ariim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      random forest\n",
      "      xgboost\n",
      "CoffsHarbour\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "Moree\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "Newcastle\n",
      "      linear regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ariim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      random forest\n",
      "      xgboost\n",
      "NorahHead\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "NorfolkIsland\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "Penrith\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "Richmond\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "Sydney\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "SydneyAirport\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "WaggaWagga\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "Williamtown\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "Wollongong\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "Canberra\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "Tuggeranong\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "MountGinini\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "Ballarat\n",
      "      linear regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ariim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      random forest\n",
      "      xgboost\n",
      "Bendigo\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "Sale\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "MelbourneAirport\n",
      "      linear regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ariim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      random forest\n",
      "      xgboost\n",
      "Melbourne\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "Mildura\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "Nhil\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "Portland\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "Watsonia\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "Dartmoor\n",
      "      linear regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ariim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      random forest\n",
      "      xgboost\n",
      "Brisbane\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "Cairns\n",
      "      linear regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ariim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      random forest\n",
      "      xgboost\n",
      "GoldCoast\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "Townsville\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "Adelaide\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "MountGambier\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "Nuriootpa\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "Woomera\n",
      "      linear regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ariim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      random forest\n",
      "      xgboost\n",
      "Albany\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "Witchcliffe\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "PearceRAAF\n",
      "      linear regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ariim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      random forest\n",
      "      xgboost\n",
      "PerthAirport\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "Perth\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "SalmonGums\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "Walpole\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "Hobart\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "Launceston\n",
      "      linear regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ariim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      random forest\n",
      "      xgboost\n",
      "AliceSprings\n",
      "      linear regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ariim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      random forest\n",
      "      xgboost\n",
      "Darwin\n",
      "      linear regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ariim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      random forest\n",
      "      xgboost\n",
      "Katherine\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n",
      "Uluru\n",
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n"
     ]
    }
   ],
   "source": [
    "resultat_models_par_loc={}\n",
    "for loc in df.Location.unique().tolist():\n",
    "    print(loc)\n",
    "    resultat_models_par_loc[loc]=modelise(df,loc,\"RainTomorrow\",{\"Yes\":1,\"No\":0},md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('per_location_models', 'wb') as file:\n",
    "    pickle.dump(resultat_models_par_loc, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      linear regression\n",
      "      random forest\n",
      "      xgboost\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-cf285892dcb4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresultat_models_gal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodelise_gal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"RainTomorrow\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"Yes\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"No\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-ac9f869e93f2>\u001b[0m in \u001b[0;36mmodelise_gal\u001b[1;34m(df, y, map_y, model_list)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"     \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"name\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"param\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"f1\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrefit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'f1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mret\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"name\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"estimator\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"best_param\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"score\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;34m\"scaler\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"X_test\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"y_test\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    708\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1149\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1151\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    687\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 689\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1017\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1018\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    907\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    910\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    561\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    425\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "resultat_models_gal=modelise_gal(df,\"RainTomorrow\",{\"Yes\":1,\"No\":0},md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('General_models', 'wb') as file:\n",
    "    pickle.dump(resultat_models_gal, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
